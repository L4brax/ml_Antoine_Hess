{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22571, 4)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd       \n",
    "train = pd.read_csv(\"Andy-Weir-The-Martian.csv\", sep='\\t', error_bad_lines=False, \n",
    "                    header=None, names=['reviewScore','link','reviewTitle','reviewText'])\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewScore</th>\n",
       "      <th>reviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>&lt;span class=\"a-size-base review-text\"&gt;I'm a ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>&lt;span class=\"a-size-base review-text\"&gt;\"I'm str...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>&lt;span class=\"a-size-base review-text\"&gt;A futuri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>&lt;span class=\"a-size-base review-text\"&gt;Follow t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>&lt;span class=\"a-size-base review-text\"&gt;This is ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reviewScore                                         reviewText\n",
       "0          4.0  <span class=\"a-size-base review-text\">I'm a ha...\n",
       "1          3.0  <span class=\"a-size-base review-text\">\"I'm str...\n",
       "2          4.0  <span class=\"a-size-base review-text\">A futuri...\n",
       "3          5.0  <span class=\"a-size-base review-text\">Follow t...\n",
       "4          5.0  <span class=\"a-size-base review-text\">This is ..."
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.drop(\"link\",1)\n",
    "train = train.drop(\"reviewTitle\", 1)\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<span class=\"a-size-base review-text\">Follow the adventure of an astronaut as he tries to survive being left on Mars.<br/>During a mission abort of the Ares 3 Mars landing, astronaut Mark Watney is thought dead as the rest of the crew does an emergency evacuation from the surface of Mars. Follow Mark as he fights to survive on a planet that really doesn't like living things.<br/>The author, Andy Weir, wrote this over a long period of time in a serial format and I waited patiently for every chapter. Now that it is complete it is even better. Thank you Andy.</span>\n"
     ]
    }
   ],
   "source": [
    "print train[\"reviewText\"][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text initial :\n",
      "<span class=\"a-size-base review-text\">Follow the adventure of an astronaut as he tries to survive being left on Mars.<br/>During a mission abort of the Ares 3 Mars landing, astronaut Mark Watney is thought dead as the rest of the crew does an emergency evacuation from the surface of Mars. Follow Mark as he fights to survive on a planet that really doesn't like living things.<br/>The author, Andy Weir, wrote this over a long period of time in a serial format and I waited patiently for every chapter. Now that it is complete it is even better. Thank you Andy.</span>\n",
      "\n",
      "Text traité :\n",
      "Follow the adventure of an astronaut as he tries to survive being left on Mars.During a mission abort of the Ares 3 Mars landing, astronaut Mark Watney is thought dead as the rest of the crew does an emergency evacuation from the surface of Mars. Follow Mark as he fights to survive on a planet that really doesn't like living things.The author, Andy Weir, wrote this over a long period of time in a serial format and I waited patiently for every chapter. Now that it is complete it is even better. Thank you Andy.\n"
     ]
    }
   ],
   "source": [
    "#On utilise beautifulSoup pour effectuer un premier nettoyage\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#On initialise beautifulSoup sur un seul commentaire\n",
    "exemple1 = BeautifulSoup(train[\"reviewText\"][3], \"lxml\") \n",
    "\n",
    "#On imprime le commentaire original puis le commentaire nettoyé\n",
    "#pour obvserver la différence\n",
    "print 'Text initial :'\n",
    "print train[\"reviewText\"][3]\n",
    "print\n",
    "print 'Text traité :'\n",
    "print exemple1.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text traité :\n",
      "Follow the adventure of an astronaut as he tries to survive being left on Mars During a mission abort of the Ares   Mars landing  astronaut Mark Watney is thought dead as the rest of the crew does an emergency evacuation from the surface of Mars  Follow Mark as he fights to survive on a planet that really doesn t like living things The author  Andy Weir  wrote this over a long period of time in a serial format and I waited patiently for every chapter  Now that it is complete it is even better  Thank you Andy \n"
     ]
    }
   ],
   "source": [
    "#On utilise ensuite la librairie re afin d'utiliser des expressions regulières\n",
    "import re\n",
    "#On pourra ainsi effectuer des find and replace\n",
    "letters_only = re.sub(\"[^a-zA-Z]\",            #Le pattern recherché\n",
    "                      \" \",                    #Remplacé par\n",
    "                      exemple1.get_text())    #Le texte à manipuler\n",
    "print 'Text traité :'\n",
    "print letters_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le commentaire en minuscule :\n",
      "follow the adventure of an astronaut as he tries to survive being left on mars during a mission abort of the ares   mars landing  astronaut mark watney is thought dead as the rest of the crew does an emergency evacuation from the surface of mars  follow mark as he fights to survive on a planet that really doesn t like living things the author  andy weir  wrote this over a long period of time in a serial format and i waited patiently for every chapter  now that it is complete it is even better  thank you andy \n",
      "\n",
      "Le commentaire traité sous forme de tableau de mots uniques (avec doublons)\n",
      "[u'follow', u'the', u'adventure', u'of', u'an', u'astronaut', u'as', u'he', u'tries', u'to', u'survive', u'being', u'left', u'on', u'mars', u'during', u'a', u'mission', u'abort', u'of', u'the', u'ares', u'mars', u'landing', u'astronaut', u'mark', u'watney', u'is', u'thought', u'dead', u'as', u'the', u'rest', u'of', u'the', u'crew', u'does', u'an', u'emergency', u'evacuation', u'from', u'the', u'surface', u'of', u'mars', u'follow', u'mark', u'as', u'he', u'fights', u'to', u'survive', u'on', u'a', u'planet', u'that', u'really', u'doesn', u't', u'like', u'living', u'things', u'the', u'author', u'andy', u'weir', u'wrote', u'this', u'over', u'a', u'long', u'period', u'of', u'time', u'in', u'a', u'serial', u'format', u'and', u'i', u'waited', u'patiently', u'for', u'every', u'chapter', u'now', u'that', u'it', u'is', u'complete', u'it', u'is', u'even', u'better', u'thank', u'you', u'andy']\n"
     ]
    }
   ],
   "source": [
    "lower_case = letters_only.lower()    #On converti en minuscule\n",
    "words = lower_case.split()           #On split la review en mots uniques\n",
    "print 'Le review en minuscule :'\n",
    "print lower_case\n",
    "print\n",
    "print 'Le review traité sous forme de tableau de mots uniques (avec doublons)'\n",
    "print words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n",
      "[u'i', u'me', u'my', u'myself', u'we', u'our', u'ours', u'ourselves', u'you', u'your', u'yours', u'yourself', u'yourselves', u'he', u'him', u'his', u'himself', u'she', u'her', u'hers', u'herself', u'it', u'its', u'itself', u'they', u'them', u'their', u'theirs', u'themselves', u'what', u'which', u'who', u'whom', u'this', u'that', u'these', u'those', u'am', u'is', u'are', u'was', u'were', u'be', u'been', u'being', u'have', u'has', u'had', u'having', u'do', u'does', u'did', u'doing', u'a', u'an', u'the', u'and', u'but', u'if', u'or', u'because', u'as', u'until', u'while', u'of', u'at', u'by', u'for', u'with', u'about', u'against', u'between', u'into', u'through', u'during', u'before', u'after', u'above', u'below', u'to', u'from', u'up', u'down', u'in', u'out', u'on', u'off', u'over', u'under', u'again', u'further', u'then', u'once', u'here', u'there', u'when', u'where', u'why', u'how', u'all', u'any', u'both', u'each', u'few', u'more', u'most', u'other', u'some', u'such', u'no', u'nor', u'not', u'only', u'own', u'same', u'so', u'than', u'too', u'very', u's', u't', u'can', u'will', u'just', u'don', u'should', u'now', u'd', u'll', u'm', u'o', u're', u've', u'y', u'ain', u'aren', u'couldn', u'didn', u'doesn', u'hadn', u'hasn', u'haven', u'isn', u'ma', u'mightn', u'mustn', u'needn', u'shan', u'shouldn', u'wasn', u'weren', u'won', u'wouldn']\n"
     ]
    }
   ],
   "source": [
    "#On importe nltk et on télécharge les datasets de mots\n",
    "import nltk\n",
    "nltk.download()\n",
    "\n",
    "#On utilisera les \"stop-word\" mots inutiles pour notre cas\n",
    "from nltk.corpus import stopwords\n",
    "#Voici leur liste des mots en anglais :\n",
    "print stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'follow', u'adventure', u'astronaut', u'tries', u'survive', u'left', u'mars', u'mission', u'abort', u'ares', u'mars', u'landing', u'astronaut', u'mark', u'watney', u'thought', u'dead', u'rest', u'crew', u'emergency', u'evacuation', u'surface', u'mars', u'follow', u'mark', u'fights', u'survive', u'planet', u'really', u'like', u'living', u'things', u'author', u'andy', u'weir', u'wrote', u'long', u'period', u'time', u'serial', u'format', u'waited', u'patiently', u'every', u'chapter', u'complete', u'even', u'better', u'thank', u'andy']\n"
     ]
    }
   ],
   "source": [
    "#On retire les stop words du texte\n",
    "words = [w for w in words if not w in stopwords.words(\"english\")]\n",
    "print words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def review_to_words(raw_review):\n",
    "    # Fonciton qui convertit un review en liste de mots\n",
    "    # L'input est une chaine de caractères,\n",
    "    # La sortie est une chaine de caractères \n",
    "    #\n",
    "    # 1. On retire le HTML\n",
    "    review_text = BeautifulSoup(raw_review, \"lxml\").get_text() \n",
    "    #\n",
    "    # 2. On retire toutes les ponctuations        \n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", review_text) \n",
    "    #\n",
    "    # 3. On convertit en minuscule puis on tokenize la chaine\n",
    "    words = letters_only.lower().split()                             \n",
    "    #\n",
    "    # 4. On convertir la liste de stop words en set car python \n",
    "    #   les traite plus rapidement\n",
    "    stops = set(stopwords.words(\"english\"))                  \n",
    "    # \n",
    "    # 5. On retire les stop words\n",
    "    processed_words = [w for w in words if not w in stops]   \n",
    "    #\n",
    "    # 6. On retourne le résultat en une seule chaine séparée par un espace.\n",
    "    return( \" \".join( processed_words )) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review traité par la fonction :\n",
      "follow adventure astronaut tries survive left mars mission abort ares mars landing astronaut mark watney thought dead rest crew emergency evacuation surface mars follow mark fights survive planet really like living things author andy weir wrote long period time serial format waited patiently every chapter complete even better thank andy\n"
     ]
    }
   ],
   "source": [
    "#Test de la fonction\n",
    "clean_review = review_to_words( train[\"reviewText\"][3] )\n",
    "print 'Review traité par la fonction :'\n",
    "print clean_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 5000 of 22571 done.\n",
      "Review 10000 of 22571 done.\n",
      "Review 15000 of 22571 done.\n",
      "Review 20000 of 22571 done.\n",
      "All reviews processed.\n"
     ]
    }
   ],
   "source": [
    "#On récupère le nombre de review\n",
    "num_reviews = train[\"reviewText\"].size\n",
    "\n",
    "#On initialise une liste vide pour contenir tous les reviews\n",
    "clean_train_reviews = []\n",
    "\n",
    "#On itère sur chaque review\n",
    "for i in xrange(0, num_reviews):\n",
    "    if( (i+1)%5000 == 0 ):\n",
    "        print \"Review %d of %d done.\" % ( i+1, num_reviews )\n",
    "    clean_train_reviews.append(review_to_words(train[\"reviewText\"][i]))\n",
    "print 'All reviews processed.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the bag of words...\n",
      "\n",
      "(22571L, 5000L)\n"
     ]
    }
   ],
   "source": [
    "print \"Creating the bag of words...\\n\"\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "#On utilise CountVectorizer, qui est l'outil bag of words de sklearn\n",
    "#On initialise le max_feature à 5000, ce qui veut dire que notre\n",
    "#dictionnaire de mot aura une taille maximum de 5000.\n",
    "vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = None,   \\\n",
    "                             max_features = 5000) \n",
    "\n",
    "#fit_transform prépare le modèle, apprend le vocabulaire et transforme nos données en vecteurs.\n",
    "#L'input est une liste de chaine de caractères.\n",
    "train_data_features = vectorizer.fit_transform(clean_train_reviews)\n",
    "\n",
    "#On convertit ensuite le résultat sous forme de tableau\n",
    "train_data_features = train_data_features.toarray()\n",
    "print train_data_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1332 also\n",
      "1050 amazing\n",
      "1767 andy\n",
      "1435 astronaut\n",
      "2297 author\n",
      "1066 believable\n",
      "1924 best\n",
      "1276 bit\n",
      "19312 book\n",
      "1830 books\n",
      "3479 character\n",
      "1663 characters\n",
      "2592 could\n",
      "1263 end\n",
      "2244 enjoyed\n",
      "1112 enough\n",
      "1059 entertaining\n",
      "1910 even\n",
      "1111 every\n",
      "1219 excellent\n",
      "1960 fi\n",
      "2873 fiction\n",
      "2217 first\n",
      "1109 found\n",
      "1722 fun\n",
      "1358 funny\n",
      "2089 get\n",
      "1038 go\n",
      "1163 going\n",
      "4221 good\n",
      "1002 got\n",
      "6867 great\n",
      "1753 hard\n",
      "1318 highly\n",
      "2457 humor\n",
      "1617 interesting\n",
      "1329 know\n",
      "4145 like\n",
      "1421 little\n",
      "1229 long\n",
      "1509 lot\n",
      "1722 love\n",
      "2759 loved\n",
      "1346 made\n",
      "1896 main\n",
      "1559 make\n",
      "1021 makes\n",
      "1255 many\n",
      "3214 mark\n",
      "4886 mars\n",
      "2422 martian\n",
      "4368 movie\n",
      "2647 much\n",
      "1212 nasa\n",
      "1156 never\n",
      "1052 next\n",
      "2359 novel\n",
      "4794 one\n",
      "1428 page\n",
      "1002 people\n",
      "1060 plot\n",
      "3090 put\n",
      "12624 read\n",
      "1052 reader\n",
      "3051 reading\n",
      "1430 real\n",
      "3643 really\n",
      "1739 recommend\n",
      "2005 sci\n",
      "7804 science\n",
      "1086 scientific\n",
      "1876 see\n",
      "1034 sense\n",
      "2196 space\n",
      "8164 story\n",
      "1784 survival\n",
      "1548 survive\n",
      "2542 technical\n",
      "1406 think\n",
      "1176 thought\n",
      "2629 time\n",
      "1149 times\n",
      "1281 wait\n",
      "1080 want\n",
      "3064 watney\n",
      "2277 way\n",
      "2878 weir\n",
      "3878 well\n",
      "3963 would\n",
      "1201 writing\n",
      "2013 written\n"
     ]
    }
   ],
   "source": [
    "#On affiche le vocabulaire\n",
    "vocab = vectorizer.get_feature_names()\n",
    "import numpy as np\n",
    "\n",
    "# On fait la somme de chaque mot du vocabulaire\n",
    "dist = np.sum(train_data_features, axis=0)\n",
    "\n",
    "#FOn affiche tous les mots aparraissant plus de 1000 fois.\n",
    "for tag, count in zip(vocab, dist):\n",
    "    if count > 1000 :\n",
    "        print count, tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the random forest...\n",
      " ...Done\n"
     ]
    }
   ],
   "source": [
    "print \"Training the random forest...\"\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# On initialise un Random Forest classifier avec 100 arbres\n",
    "forest = RandomForestClassifier(n_estimators = 100) \n",
    "\n",
    "# On ajuste le modèle sur le training set, en utilisant le bag of words comme feature \n",
    "# et le score comme la variable de réponse \n",
    "#\n",
    "# Peut prendre quelques minutes\n",
    "forest = forest.fit( train_data_features, train[\"reviewScore\"] )\n",
    "print ' ...Done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22861, 4)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# On Créé le nouveau dataframe qui servira de test\n",
    "test = pd.read_csv(\"Donna-Tartt-The-Goldfinch.csv\", sep='\\t', error_bad_lines=False, \n",
    "                    header=None, names=['reviewScore','link','reviewTitle','reviewText'])\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewScore</th>\n",
       "      <th>reviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>&lt;span class=\"a-size-base review-text\"&gt;I won't ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>&lt;span class=\"a-size-base review-text\"&gt;It's bee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>&lt;span class=\"a-size-base review-text\"&gt;I passed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>&lt;span class=\"a-size-base review-text\"&gt;This boo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>&lt;span class=\"a-size-base review-text\"&gt;This was...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reviewScore                                         reviewText\n",
       "0          5.0  <span class=\"a-size-base review-text\">I won't ...\n",
       "1          3.0  <span class=\"a-size-base review-text\">It's bee...\n",
       "2          3.0  <span class=\"a-size-base review-text\">I passed...\n",
       "3          3.0  <span class=\"a-size-base review-text\">This boo...\n",
       "4          5.0  <span class=\"a-size-base review-text\">This was..."
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = test.drop(\"link\",1)\n",
    "test = test.drop(\"reviewTitle\", 1)\n",
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 5000 of 22861 done\n",
      "Review 10000 of 22861 done\n",
      "Review 15000 of 22861 done\n",
      "Review 20000 of 22861 done\n",
      "All reviews processed.\n"
     ]
    }
   ],
   "source": [
    "# On créé une liste vide qui contiendra les reviews traitées.\n",
    "num_reviews = len(test[\"reviewText\"])\n",
    "clean_test_reviews = [] \n",
    "\n",
    "for i in xrange(0,num_reviews):\n",
    "    if( (i+1) % 5000 == 0 ):\n",
    "        print \"Review %d of %d done\" % (i+1, num_reviews)\n",
    "    clean_review = review_to_words( test[\"reviewText\"][i] )\n",
    "    clean_test_reviews.append( clean_review )\n",
    "print 'All reviews processed.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the bag of words...\n",
      "\n",
      "(22571L, 5000L)\n"
     ]
    }
   ],
   "source": [
    "# On créé un bag of words pour le test set et on l'insère dans un numpy array\n",
    "print \"Creating the bag of words...\\n\"\n",
    "test_data_features = vectorizer.transform(clean_test_reviews)\n",
    "test_data_features = test_data_features.toarray()\n",
    "print train_data_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done !\n"
     ]
    }
   ],
   "source": [
    "# On utilise random forest afin de créer la prédiction\n",
    "result = forest.predict(test_data_features)\n",
    "\n",
    "# On ajoute le resultat dans un dataframe\n",
    "output = pd.DataFrame( data={ \"reviewScore\":result} )\n",
    "print \"Done !\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewScore</th>\n",
       "      <th>reviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>&lt;span class=\"a-size-base review-text\"&gt;I won't ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>&lt;span class=\"a-size-base review-text\"&gt;It's bee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>&lt;span class=\"a-size-base review-text\"&gt;I passed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>&lt;span class=\"a-size-base review-text\"&gt;This boo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>&lt;span class=\"a-size-base review-text\"&gt;This was...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reviewScore                                         reviewText\n",
       "0          5.0  <span class=\"a-size-base review-text\">I won't ...\n",
       "1          3.0  <span class=\"a-size-base review-text\">It's bee...\n",
       "2          3.0  <span class=\"a-size-base review-text\">I passed...\n",
       "3          3.0  <span class=\"a-size-base review-text\">This boo...\n",
       "4          5.0  <span class=\"a-size-base review-text\">This was..."
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewScore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reviewScore\n",
       "0          5.0\n",
       "1          4.0\n",
       "2          4.0\n",
       "3          5.0\n",
       "4          5.0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV created !\n"
     ]
    }
   ],
   "source": [
    "# On créé un fichier csv de ces résultats avec pandas\n",
    "output.to_csv( \"Bag_of_Words_model.csv\", index=False, quoting=3 )\n",
    "print \"CSV created !\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
